{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "seed = 1337\n",
    "np.random.seed(seed)\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "max_words = 1000\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2, seed=seed)\n",
    "num_classes = np.max(y_train) + 1  # 46 topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training features are still simply sequences of indexes and we need to further preprocess them, so that we can plug them into a Dense layer. For this we use a Tokenizer from Keras' text preprocessing module. This tokenizer will take an index sequence and map it to a vector of length max_words=1000. Each of the 1000 vector positions corresponds to one of the words in our newswire corpus. The output of the tokenizer has a 1 at the i-th position of the vector, if the word corresponding to i is in the description of the newswire, and 0 otherwise. Even if this word appears multiple times, we still just put a 1 into our vector, i.e. our tokenizer is binary. We use this tokenizer to transform both train and test features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # Instantiate sequential model\n",
    "model.add(Dense(512,input_shape=(max_words,), activation='relu')) # Add first layer. Make sure to specify input shape\n",
    "model.add(Dropout(0.5)) # Add second layer\n",
    "model.add(Dense(num_classes, activation='softmax')) # Add third layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "281/281 [==============================] - ETA: 0s - loss: 1.3967 - accuracy: 0.68 - 2s 8ms/step - loss: 1.3951 - accuracy: 0.6889\n",
      "Epoch 2/5\n",
      "281/281 [==============================] - 2s 7ms/step - loss: 0.7690 - accuracy: 0.8202\n",
      "Epoch 3/5\n",
      "281/281 [==============================] - 2s 7ms/step - loss: 0.5519 - accuracy: 0.8667\n",
      "Epoch 4/5\n",
      "281/281 [==============================] - 2s 8ms/step - loss: 0.4273 - accuracy: 0.8948: 0s -\n",
      "Epoch 5/5\n",
      "281/281 [==============================] - 2s 7ms/step - loss: 0.3456 - accuracy: 0.9100\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.8670 - accuracy: 0.8019\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(x_train,y_train, batch_size=32, epochs=5)\n",
    "score = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8018699884414673"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.44882137e-03, 7.87596218e-03, 1.57368326e-04, 3.97504568e-01,\n",
       "        4.23457682e-01, 9.51814291e-05, 6.94357848e-04, 1.01682718e-03,\n",
       "        1.56979598e-02, 8.23450915e-04, 1.37718150e-03, 2.32385425e-03,\n",
       "        1.43272663e-03, 5.88555308e-03, 1.07950135e-03, 5.81469329e-04,\n",
       "        5.91767356e-02, 2.91323802e-03, 7.38388393e-04, 2.54020933e-03,\n",
       "        4.24878560e-02, 2.34191981e-03, 1.06367021e-04, 1.34405622e-04,\n",
       "        1.81944226e-04, 1.41939119e-04, 4.64409764e-04, 9.11555369e-04,\n",
       "        9.87651758e-04, 7.09041138e-04, 1.78137352e-03, 2.27235071e-03,\n",
       "        6.71273971e-04, 2.47770135e-04, 1.80374819e-03, 1.59920484e-04,\n",
       "        1.22340629e-03, 9.38723329e-04, 8.01622286e-04, 6.38812268e-03,\n",
       "        1.05531508e-04, 5.85148670e-03, 1.69325634e-04, 1.08387889e-04,\n",
       "        5.23469171e-05, 1.36540315e-04],\n",
       "       [1.87256825e-04, 2.23800048e-01, 2.85247603e-04, 6.89064059e-03,\n",
       "        3.45291048e-02, 1.95299697e-04, 3.53117830e-05, 5.29146404e-04,\n",
       "        3.09590716e-02, 2.33339888e-04, 3.47213179e-04, 1.57903205e-03,\n",
       "        3.89662548e-03, 3.75176081e-03, 3.87936900e-03, 8.80727239e-05,\n",
       "        9.61767416e-03, 5.47886411e-05, 3.43107316e-03, 6.43557966e-01,\n",
       "        1.73158832e-02, 1.35840254e-03, 1.93860629e-04, 2.43218336e-03,\n",
       "        3.19583720e-04, 1.44728750e-03, 8.83891844e-05, 5.15600987e-05,\n",
       "        3.08532384e-04, 3.62510909e-05, 6.13194483e-04, 2.07931123e-04,\n",
       "        1.97217567e-04, 2.42205078e-05, 2.20455369e-03, 3.68300913e-04,\n",
       "        4.60264011e-04, 9.89830660e-05, 1.15394581e-03, 6.85891428e-05,\n",
       "        1.44071120e-03, 2.24266201e-04, 1.24618062e-03, 1.80938529e-04,\n",
       "        7.52953856e-05, 3.54328877e-05],\n",
       "       [7.98915062e-06, 6.83280814e-05, 3.20013260e-06, 6.03217538e-03,\n",
       "        9.93510067e-01, 4.39354238e-07, 3.63553272e-06, 9.17112118e-07,\n",
       "        2.55939062e-06, 7.78831873e-06, 4.23376559e-06, 3.40860461e-05,\n",
       "        1.31527952e-06, 8.77182174e-06, 3.61389851e-07, 4.01792306e-07,\n",
       "        2.80705244e-05, 2.38731923e-06, 2.77675122e-06, 1.47543760e-04,\n",
       "        7.30134125e-05, 1.33659626e-06, 6.00012768e-08, 7.56963300e-06,\n",
       "        1.33490776e-05, 1.15940475e-06, 7.59853833e-07, 3.01733894e-06,\n",
       "        2.72640136e-06, 1.19752471e-07, 1.27248052e-06, 6.80290850e-06,\n",
       "        8.99045176e-07, 1.88471489e-07, 1.76885578e-06, 2.72820500e-07,\n",
       "        7.64189451e-07, 6.45176726e-07, 3.02441458e-06, 5.93063214e-06,\n",
       "        1.44999001e-06, 2.73615365e-06, 8.73323700e-07, 2.14853299e-06,\n",
       "        1.73037279e-07, 9.50845958e-07],\n",
       "       [4.44533907e-05, 2.88277399e-04, 6.77572825e-05, 9.91236448e-01,\n",
       "        1.87375350e-03, 2.01300554e-06, 6.58711633e-06, 7.00585269e-06,\n",
       "        1.56712646e-04, 7.69312246e-05, 7.68719619e-05, 1.35708484e-04,\n",
       "        3.13286000e-05, 7.80134433e-05, 1.29403888e-05, 3.24680514e-06,\n",
       "        6.31869189e-04, 3.24390498e-06, 1.98662692e-05, 2.53617391e-03,\n",
       "        2.28568004e-03, 2.09483696e-05, 3.00201646e-06, 1.10810324e-04,\n",
       "        4.70563573e-05, 9.28912777e-06, 2.86245495e-06, 1.06327809e-06,\n",
       "        2.69567663e-05, 1.63317000e-05, 8.30590943e-06, 3.33275348e-05,\n",
       "        4.28824023e-06, 3.26501026e-06, 1.33873964e-05, 1.84269288e-06,\n",
       "        2.96426879e-05, 2.09020927e-05, 3.40144652e-05, 1.42569806e-05,\n",
       "        4.27908117e-06, 9.86160194e-06, 4.89504964e-06, 5.66367078e-07,\n",
       "        1.40624945e-06, 2.92909272e-06],\n",
       "       [5.10981681e-06, 9.65877261e-05, 4.71008252e-06, 9.96288657e-01,\n",
       "        2.59468704e-03, 3.39229132e-07, 5.22401535e-07, 1.52491236e-06,\n",
       "        1.35597220e-04, 4.01381385e-06, 1.99491569e-05, 3.51360068e-04,\n",
       "        6.22093648e-05, 3.27425505e-06, 2.12847613e-06, 1.95645089e-06,\n",
       "        9.22036852e-05, 5.18763443e-07, 1.21909363e-06, 1.44129284e-04,\n",
       "        5.45685798e-05, 1.23602274e-06, 3.12284897e-07, 8.04968749e-06,\n",
       "        5.66830931e-06, 8.28336738e-07, 4.52105184e-07, 1.42939001e-07,\n",
       "        4.26019142e-06, 3.16595970e-06, 3.10159777e-07, 1.55519763e-06,\n",
       "        1.88942010e-07, 1.39483276e-07, 3.26872669e-06, 3.16258451e-07,\n",
       "        2.59699682e-05, 1.75528055e-06, 7.11963003e-05, 4.94733797e-07,\n",
       "        2.11511087e-06, 9.21387198e-07, 5.82305461e-07, 2.55991779e-07,\n",
       "        1.01236196e-06, 2.89283264e-07]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
